[base]
env_name = pokemon_pinball
package = custom
policy_name = PokemonPinballPolicy
rnn_name = None
vec = multiprocessing
vec_overwork = False

[env]
rom_path = ./roms/pokemon_pinball.gbc
episode_mode = life
reset_condition = game
reward_shaping = comprehensive
info_level = 2
visual_mode = screen
frame_skip = 4
reduce_screen_resolution = True
headless = True
debug = False

[policy]
hidden_size = 512
cnn_channels = [32, 64, 64]

[rnn]
# No RNN for now

[train]
device = cuda
seed = 42
torch_deterministic = True

# Environment setup
num_envs = 64
num_workers = 8
env_batch_size = 8
zero_copy = True

# Training hyperparameters
total_timesteps = 10000000
batch_size = 32768
minibatch_size = 8192
bptt_horizon = 16
learning_rate = 0.0003
gamma = 0.99
gae_lambda = 0.95
update_epochs = 4
clip_coef = 0.2
ent_coef = 0.01
vf_coef = 0.5
vf_clip_coef = 0.1
max_grad_norm = 0.5
norm_adv = True
clip_vloss = True
target_kl = None
anneal_lr = True

# Technical
compile = False
compile_mode = default
cpu_offload = False

# Checkpointing
checkpoint_interval = 100
data_dir = ./experiments

[wandb]
project = pokemon-pinball-pufferlib
group = experiments
track = True

[sweep]
# todo